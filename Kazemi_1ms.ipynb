{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random as rand\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to implement he gradient boosting algorithm as implemented in the Kazemi 1 ms face alignment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Open(loc):\n",
    "    l = []\n",
    "    file_ptr = open(loc, \"r\")\n",
    "    image_name = file_ptr.readline()\n",
    "    for x in file_ptr:\n",
    "        k = x.split(',')\n",
    "        k[1] = k[1].split('\\n')[0]\n",
    "        k[0] = float(k[0])\n",
    "        k[1] = float(k[1])\n",
    "        l.append(k)\n",
    "    return image_name.split(\"\\n\")[0] , l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Face_detection(img):\n",
    "    #cnts = []\n",
    "    img = cv2.imread(img)\n",
    "    #copy = img.copy()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faceCascade = cv2.CascadeClassifier('haarcascades\\haarcascade_frontalface_default.xml')\n",
    "    faces = faceCascade.detectMultiScale(gray,1.1,2)\n",
    "    \n",
    "    max_val = -1\n",
    "    val = [0, 0, 0, 0]\n",
    "    for (x,y,w,h) in faces:\n",
    "        if w*h >= max_val:\n",
    "            val[0] = x\n",
    "            val[1] = y\n",
    "            val[2] = w\n",
    "            val[3] = h\n",
    "            max_val = w*h\n",
    "    \n",
    "    #    cv2.rectangle(copy,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "    #for i in range(194):\n",
    "    #    cv2.circle(copy,(int(k[index_k][i][0]),int(k[index_k][i][1])),2,(0,0,255),-1)\n",
    "\n",
    "    #resized = imutils.resize(copy,width=500)  \n",
    "    return val[0], val[1], val[2], val[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "[309.86, 450.98] [-4.4934722609468736e-11, 1.9269918993813917e-11]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-664ae6fcb446>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mBounding_box\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mShape_estimate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage_Vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGroundTruth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBounding_box\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-72-664ae6fcb446>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(N)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mBounding_box\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mShape_estimate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage_Vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGroundTruth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBounding_box\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-4b0a399c2c5c>\u001b[0m in \u001b[0;36mdriver\u001b[1;34m(Image_vectors, GroundTruth, Bounding_box, Number_of_strong_regression)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mNumber_of_strong_regression\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGroundTruth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mShape_estimate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDelta_S\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBounding_box\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mShape_estimate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-05baa54476c1>\u001b[0m in \u001b[0;36mGradientBoost\u001b[1;34m(Image_vectors, GroundTruth, Shape_estimate, target_Update_step, Number_of_training_samples, learning_rate, Bounding_box, Number_of_regressors)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNumber_of_training_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_Update_step\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_Update_step\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "def main(N):\n",
    "    TRAIN_DIR = 'train_1/'\n",
    "    annotations = 'annotation/'\n",
    "    GroundTruth = []\n",
    "    Image_Vectors = []\n",
    "    x0 = 0\n",
    "    y0 = 0\n",
    "    h0 = 0 \n",
    "    w0 = 0 \n",
    "\n",
    "    for i in range(1, N+1):\n",
    "        print(i)\n",
    "        img , gt = Open(annotations+str(i)+\".txt\")\n",
    "        GroundTruth.append(gt)\n",
    "        Image_Vectors.append(TRAIN_DIR + str(img) + \".jpg\")\n",
    "        x, y, h, w = Face_detection(Image_Vectors[i-1])\n",
    "        x0 += x\n",
    "        y0 += y\n",
    "        h0 += h\n",
    "        w0 += w\n",
    "    \n",
    "    Bounding_box = [x0/N, y0/N, h0/N, w0/N]\n",
    "    Shape_estimate = driver(Image_Vectors, GroundTruth, Bounding_box)\n",
    "main(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver(Image_vectors, GroundTruth, Bounding_box, Number_of_strong_regression = 10):\n",
    "    \n",
    "    Shape_estimate = []\n",
    "    Delta_S = []\n",
    "    for i in range(len(Image_vectors)):\n",
    "        index = rand.randint(0, len(Image_vectors)-1)\n",
    "        while index == i:\n",
    "            index = rand.randint(0, len(Image_vectors)-1)\n",
    "        val = GroundTruth[index]\n",
    "        Shape_estimate.append(val)\n",
    "        for j in range(len(GroundTruth[0])):\n",
    "            Delta_S.append([GroundTruth[i][j][0] - val[j][0] ,GroundTruth[i][j][1] - val[j][1]])\n",
    "    learning_rate = 0.7\n",
    "    \n",
    "    while Number_of_strong_regression > 0:\n",
    "        r = GradientBoost(Image_vectors, GroundTruth, Shape_estimate, Delta_S, len(Image_vectors), learning_rate, Bounding_box)\n",
    "        for i in range(len(Image_vectors)):\n",
    "            Shape_estimate[i] += r\n",
    "            Delta_S[i] = (GroundTruth[i] - Shape_estimate[i])\n",
    "        \n",
    "        Number_of_strong_regression -= 1\n",
    "    \n",
    "    return Shape_estimate\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientBoost(Image_vectors, GroundTruth, Shape_estimate, target_Update_step, Number_of_training_samples, learning_rate, Bounding_box, Number_of_regressors = 20):\n",
    "    \n",
    "    '''\n",
    "    Image_Vectors: dim(N, dim(of each image)): It is the set of all the images\n",
    "    Shape_estimate: dim(N, dim(landmarks)): It is the set of all the landmarks \n",
    "    target_Update_step: dim(N, dim(landmarks)): It is the set of all pseudo-residuals\n",
    "    Number_of_regressors(weak): K(20)\n",
    "    Number_of_training_samples: n\n",
    "    learning_rate: v\n",
    "    '''\n",
    "    \n",
    "\n",
    "    \n",
    "    #Initialise \n",
    "    S_temp  = [0]*len(target_Update_step[0])\n",
    "    \n",
    "    for i in range(len(target_Update_step)):\n",
    "        for j in range(len(target_Update_step[i])):\n",
    "            S_temp[j] += target_Update_step[i][j]\n",
    "            \n",
    "    f = [X/len(S_temp) for X in S_temp]\n",
    "    \n",
    "    \n",
    "    #In loop\n",
    "    for k in range(Number_of_regressors):\n",
    "        \n",
    "        r = []\n",
    "        for i in range(Number_of_training_samples):\n",
    "            print(target_Update_step[i] , f)\n",
    "            r.append(target_Update_step[i] - f)\n",
    "        \n",
    "        ret = []\n",
    "        fit_regressor(Image_vectors, GroundTruth, r, Shape_estimate, Mean_Shape_estimate, Image_vectors, ret, Bounding_box)\n",
    "            \n",
    "        f += learning_rate*np.mean(ret)\n",
    "    \n",
    "    return f\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_regressor(I, r, GroundTruth, Shape_estimate, Mean_Shape_estimate, Q, ret_Shape_Estimate, Bounding_box, levels = 5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Q: it is the set of all images at current node before split occurs\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #bucktes = []\n",
    "    #splits = []\n",
    "    if levels == 0:\n",
    "        #Each image find S_pi_i and Subtract from Shape_estimate \n",
    "        #return Q\n",
    "        delta_S = 0\n",
    "        for img in Q:\n",
    "            index = I.index(img)\n",
    "            S_pi_i = GroundTruth[index]\n",
    "            delta_S  += S_pi_i - Shape_estimate[index]\n",
    "        \n",
    "        ret_Shape_Estimate.append(delta_S/len(Q))\n",
    "            \n",
    "        return None\n",
    "        \n",
    "        \n",
    "    Ql, Qr = get_Best_Split_for_Node(I, r, Q, Shape_estimate, Mean_Shape_estimate, box)\n",
    "    fit_regressor(I, r, Shape_estimate, Mean_Shape_estimate, Ql, splits, Bounding_box, levels - 1)\n",
    "    fit_regressor(I, r, Shape_estimate, Mean_Shape_estimate, Qr, splits, Bounding_box, levels - 1)\n",
    "    \n",
    "    #for l in levels:\n",
    "    #    Ql1, Qr1, split_l =  get_Best_Split_for_Node(I, r, Ql, Shape_estimate, Mean_Shape_estimate)\n",
    "    #    Ql, Qr, split_r = get_Best_Split_for_Node(I, r, Qr, Shape_estimate, Mean_Shape_estimate)\n",
    "\n",
    "    \n",
    "\n",
    "def get_Best_Split_for_Node(I, r, Q, Shape_estimate, Mean_Shape_estimate, box):\n",
    "    Candidate_splits = get_Candidate_splits(I, box)\n",
    "    for ele in Candidate_splits:\n",
    "        s, r, t = SimilarityTransform(Shape_estimate, Mean_Shape_estimate) #change the func to get the mean from outside source\n",
    "        \n",
    "        for i in range(0, 2):\n",
    "            closest_landmark = getClosestLandmark(Mean_Shape_estimate, ele[i])\n",
    "            offset = [a-b for a, b in zip(ele, closest_landmark)]\n",
    "            u_dash = getClosestLandmark(Shape_estimate, ele[i]) + (1/s)*np.transpose(r)*offset\n",
    "            #new_u_v.append(u_dash)\n",
    "            ele[i] = u_dash\n",
    "        \n",
    "    Ql = []\n",
    "    Qr = []\n",
    "    for split in Candidate_splits:\n",
    "        left, right = check_Intensity(I, split)\n",
    "        Ql.append(left)\n",
    "        Qr.append(right)\n",
    "        \n",
    "    \n",
    "    \n",
    "    u = (1/len(Q))*np.sum(r)\n",
    "    \n",
    "    u_Ql = []\n",
    "    for i in range(len(Ql)):\n",
    "        for ele in Ql[i]:\n",
    "            u_Ql[i] += r.index(ele)\n",
    "        u_Ql[i] /= len(Ql[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    for i in range(len(u_Ql)):\n",
    "        u_Qr[i] = (len(Q))*u - len(Ql[i])*u_Ql[i]\n",
    "        u_Qr[i] = np.divide(u_Qr[i], Qr[i])\n",
    "        \n",
    "    E_Qtheta = []\n",
    "    for i in range(len(u_Ql)):\n",
    "        E_Qtheta.append(len(Ql)*np.dot(np.transpose(u_Ql), u_Ql) + len(Qr)*np.dot(np.transpose(u_Qr), u_Qr))\n",
    "    \n",
    "    best_split = E_Qtheta.index(max(E_Qtheta))\n",
    "    \n",
    "    return Ql[best_split], Qr[best_split]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_Intensity(I, theta):\n",
    "    left = []\n",
    "    right = []\n",
    "    for img in I:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #gray[theta[0]][0]\n",
    "        #gray[x][y]\n",
    "        #theta[0][0] = u[0]\n",
    "        if gray[theta[0][0]][theta[0][1]] - gray[theta[1][0]][theta[1][1]] > theta[2]:\n",
    "            left.append(img)\n",
    "        else:\n",
    "            right.append(img)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Closest_Landmark(Shape_Estimate, pix):\n",
    "    \n",
    "    min_val = 0xffffffff\n",
    "    ret_pix\n",
    "    for ele in Shape_estimate:\n",
    "        dist = math.sqrt(sum(ele[0] - pix[0])**2 + (ele[1] - pix[1])**2)\n",
    "        if dist <= min_val:\n",
    "            min_val = dist\n",
    "            ret_pix = ele\n",
    "        \n",
    "    return ret_pix\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Candidate_splits(I, box, S = 20):\n",
    "    \n",
    "    '''\n",
    "    i/p: The set of all n images\n",
    "    \n",
    "    o/p: The set of candidate splits for each and every image i.e N dimension x dimension of each pixel\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Candidate_splits = []\n",
    "    \n",
    "    for i in range(S):\n",
    "        pix = get_pixels(I, box)\n",
    "        u = pix[randint(0, len(pix))]\n",
    "        v = pix[randint(0, len(pix))]\n",
    "        while not check_prior(u, v):\n",
    "            u = pix[randint(0, len(pix))]\n",
    "            v = pix[randint(0, len(pix))]\n",
    "        thresh = np.random.uniform(-0.25, 0.25) \n",
    "        Candidate_splits.append([u, v, thresh])\n",
    "    \n",
    "    return Candidate_splits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prior(u, v):\n",
    "    dist = np.absolute(np.linalg.norm(u-v)) \n",
    "    prob = np.exp(-dist/.1) \n",
    "    if u != v and prob > np.random.random(): \n",
    "        return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels(I, Bounding_box, P = 400):\n",
    "    \n",
    "    \"\"\"\n",
    "    i/p: The bounding box generated for this particular image :- I\n",
    "    (x0, y0): coordinates of the top left of the bounding box\n",
    "    h, w: height and width of the bounding box respectively\n",
    "    P: the number of pixel locations(400)\n",
    "    \n",
    "    o/p: set of P pixels in the bounding box\n",
    "    \"\"\"\n",
    "    \n",
    "    x0 = Bounding_box[0]\n",
    "    y0 = Bounding_box[1]\n",
    "    h = Bounding_box[2]\n",
    "    w = Bounding_box[3]\n",
    "    ret = []\n",
    "    for i in range(P):\n",
    "        ret_x = randint(x0, x0+w)\n",
    "        ret_y = randint(y0, y0+h)\n",
    "        ret.append([ret_x, ret_y])\n",
    "    \n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
